{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual setup of required environment variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env FND_ROOT=/workspace/fnd-building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define constants and import all randomness sources first.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration constants.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE = 0\n",
    "\n",
    "# Global original seed for randomness reproducibility.\n",
    "OG_SEED = 19012016\n",
    "\n",
    "# Prefix for storing results.\n",
    "RUN_SUFFIX = f'per_label_{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}'\n",
    "\n",
    "# Absolute path to root folder of the repository.\n",
    "FND_ROOT=%env FND_ROOT\n",
    "\n",
    "EMBEDDINGS_PREFIX=f\"{FND_ROOT}/experiments/embeddings\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize randomness sources with original seed, for full reproducibility of results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(OG_SEED)\n",
    "torch.manual_seed(OG_SEED)\n",
    "random.seed(OG_SEED)\n",
    "run_seed = np.random.randint(0, 42069, size=1)[0]\n",
    "run_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All other imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from torch import cuda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(f\"Pytorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup papermill parameters.** The cell below must be tagged with the 'parameters' tag. See: https://papermill.readthedocs.io/en/latest/usage-parameterize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameters\n",
    "\n",
    "## Must be set to True when running via papermill.\n",
    "PAPERMILL = False\n",
    "\n",
    "RUN_SETTING = \"-1\"\n",
    "\n",
    "## Whether to load pretrained model.\n",
    "LOAD_PRETRAINED_MODEL = False\n",
    "\n",
    "# Specific pre-trained model to use if\n",
    "# LOAD_PRETRAINED_MODEL is true.\n",
    "PRETRAINED_MODEL = None\n",
    "\n",
    "## Whether to save the model after specific epochs.\n",
    "SAVE_EPOCH_SNAPSHOTS = False\n",
    "\n",
    "# TODO: check how to pass the list via papermill parameters.\n",
    "# Epoch snapshots when SAVE_EPOCH_SNAPSHOTS = True\n",
    "EPOCH_SNAPSHOTS= [2, 4]\n",
    "EPOCH_SNAPSHOTS_LABELS = [\"EPOCH\", \"EPOCH_DATA\"]\n",
    "\n",
    "EXPERIMENT_SUFFIX = \"\"\n",
    "\n",
    "## Folder to store Excel result files\n",
    "XLS_RESULTS_FOLDER = \"./\"\n",
    "\n",
    "## Set to 1 to store results in S3, set to 0 otherwise.\n",
    "# Defaults to 0.\n",
    "STORE_RESULTS_S3 = 0\n",
    "\n",
    "USE_VALIDATION_SET = True\n",
    "VALIDATION_SET_SIZE = 0.15\n",
    "TEST_SET_SIZE = 0.15\n",
    "\n",
    "# Model-specific parameters\n",
    "\n",
    "# Number of epochs to run.\n",
    "# When saving snapshots, this value must be set\n",
    "# to max(EPOCH_SNAPSHOTS) + 1\n",
    "EPOCHS = 1000\n",
    "\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-04\n",
    "\n",
    "## Number of GRU Layers\n",
    "# 1: single GRU, 2+: stacked GRU\n",
    "GRU_NUM_LAYERS = 2  \n",
    "\n",
    "## Whether the GRU is bidirectional or not.\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "## Number of hidden units\n",
    "UNITS = 1024\n",
    "\n",
    "## Embedding to use for training, validation, and test.\n",
    "EMBEDDING_SNAPSHOT = \"BASE0_RN_RAW_BERT_embedding\"\n",
    "\n",
    "# Dropout value for layer after GRU\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# Dropout value inside GRU\n",
    "INTERNAL_DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EPOCH_SNAPSHOTS)\n",
    "EPOCH_SNAPSHOTS_LABELS_BY_NUM = { k: v for k, v in list(zip(EPOCH_SNAPSHOTS, EPOCH_SNAPSHOTS_LABELS)) }\n",
    "EPOCH_SNAPSHOTS_LABELS_BY_NUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clear CUDA cache and perform garbage collection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup CUDA device if GPU is available.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = f\"cuda:{CUDA_DEVICE}\" if cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(CUDA_DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run-specific settings, taken from constants and papermill parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"OG_SEED\": OG_SEED,\n",
    "    \"SAVE_EPOCH_SNAPSHOTS\": SAVE_EPOCH_SNAPSHOTS,\n",
    "    \"EPOCH_SNAPSHOTS\": EPOCH_SNAPSHOTS,\n",
    "    \"EPOCHS\": EPOCHS,    \n",
    "    \"TRAIN_BATCH_SIZE\": TRAIN_BATCH_SIZE,\n",
    "    \"VALID_BATCH_SIZE\": VALID_BATCH_SIZE,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "    \"GRU_NUM_LAYERS\": GRU_NUM_LAYERS,\n",
    "    \"BIDIRECTIONAL\": BIDIRECTIONAL,\n",
    "    \"UNITS\": UNITS,\n",
    "    \"DROPOUT\": DROPOUT,\n",
    "    \"INTERNAL_DROPOUT\": INTERNAL_DROPOUT,   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PAPERMILL:\n",
    "    print(\"Importing plain tqdm\")\n",
    "    from tqdm import tqdm    \n",
    "else:\n",
    "    print(\"Importing auto tqdm\")\n",
    "    from tqdm.auto import tqdm    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load X and y from precomputed embeddings and generate train, test, val split.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = None\n",
    "y = None\n",
    "\n",
    "print(f\"Loading Xy from snapshot {EMBEDDING_SNAPSHOT}\")\n",
    "\n",
    "X = np.load(f\"{EMBEDDINGS_PREFIX}/X_{EMBEDDING_SNAPSHOT}.npy\")\n",
    "y = np.load(f\"{EMBEDDINGS_PREFIX}/y_{EMBEDDING_SNAPSHOT}.npy\")\n",
    "\n",
    "assert X is not None\n",
    "assert y is not None\n",
    "assert len(X) == len(y)\n",
    "\n",
    "print(f\"Loaded Xy from snapshot: {EMBEDDING_SNAPSHOT}\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separaci√≥n en datos de entrenamiento y prueba\n",
    "if USE_VALIDATION_SET:\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=VALIDATION_SET_SIZE)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=TEST_SET_SIZE)\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SET_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define custom dataset loader and specify loader parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, examples, labels):\n",
    "        assert len(examples) == len(labels)\n",
    "        self.examples = examples\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        example = self.examples[index]\n",
    "\n",
    "        # From one-hot encoded to categorical label\n",
    "        label = np.argmax(self.labels[index])\n",
    "        \n",
    "        return {\n",
    "            'example': torch.tensor(example),            \n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tree_max_num_seq, emb_size = X.shape\n",
    "_, num_categories = y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tree_max_num_seq: \", tree_max_num_seq)\n",
    "print(\"emb size: \", emb_size)\n",
    "print(\"num_categories: \", num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_VALIDATION_SET:\n",
    "    print(\"Train+val shapes\")\n",
    "    print(f\"X train+val: {X_train_val.shape}\")\n",
    "    print(f\"y train+val: {y_train_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train shapes\")\n",
    "print(f\"X train: {X_train.shape}\")\n",
    "print(f\"y train: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_VALIDATION_SET:\n",
    "    print(\"Val shapes\")\n",
    "    print(f\"X val: {X_val.shape}\")\n",
    "    print(f\"y val: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test shapes\")\n",
    "print(f\"X test: {X_test.shape}\")\n",
    "print(f\"y test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size': settings[\"TRAIN_BATCH_SIZE\"],\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}\n",
    "\n",
    "validate_params = {\n",
    "    'batch_size': settings[\"VALID_BATCH_SIZE\"],\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}\n",
    "\n",
    "test_params = {\n",
    "    'batch_size': settings[\"VALID_BATCH_SIZE\"],\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bidirectional Stacked GRU for fake news detection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FND_BI_GRU(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional GRU for fake news classification.\n",
    "\n",
    "    Pytorch reimplementation of model in Providel&Mendoza (2020).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # _tree_max_num_seq,\n",
    "        _emb_size,\n",
    "        _units=200,\n",
    "        _num_layers=2,\n",
    "        _num_categories=2,\n",
    "        _bidirectional=True,\n",
    "        _internal_dropout=0.1,\n",
    "        _dropout=0.1,\n",
    "    ):\n",
    "        super(FND_BI_GRU, self).__init__()\n",
    "\n",
    "        self.input_size = _emb_size\n",
    "        self.hidden_size = _units\n",
    "        self.num_layers = _num_layers # GRU_NUM_LAYERS\n",
    "        self.output_size = _num_categories\n",
    "        self.bidirectional = _bidirectional # BIDIRECTIONAL\n",
    "        self.bidirectional_factor = 2 if self.bidirectional else 1\n",
    "\n",
    "        self.gru = torch.nn.GRU(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=self.bidirectional,\n",
    "            dropout=_internal_dropout,\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(_dropout)\n",
    "        self.fc = torch.nn.Linear(\n",
    "            self.hidden_size * self.bidirectional_factor, 1 # 1 because it's binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply GRU.\n",
    "        h0 = torch.zeros(\n",
    "            self.num_layers * self.bidirectional_factor, x.size(0), self.hidden_size\n",
    "        ).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "\n",
    "        # Apply dropout.\n",
    "        out = self.dropout(\n",
    "            out[:, -1, :]\n",
    "        )  \n",
    "\n",
    "        # Apply linear layer.\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define traning, test, and validation procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, training_loader, optimizer=None, scheduler=None):\n",
    "    \n",
    "    model.train()\n",
    "    loss_acum = 0\n",
    "    N = 0\n",
    "    \n",
    "    for iters, data in tqdm(enumerate(training_loader, 0), total=len(training_loader)):\n",
    "\n",
    "        # Reset optimizer gradients.\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Make forward and backward passes in the model.\n",
    "        x = data[\"example\"].to(device)\n",
    "        targets = data[\"label\"].to(device)\n",
    "        logits = model(x)\n",
    "        logits = logits.squeeze(1)\n",
    "        \n",
    "        loss = loss_fn(logits, targets.float())\n",
    "        loss.backward()\n",
    "\n",
    "        # Compute accumulated loss for reporting progress.\n",
    "        loss_acum += loss.item()\n",
    "        N = N + 1\n",
    "\n",
    "        # Update optimizer and scheduler, if any.\n",
    "        if optimizer:\n",
    "            optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "    return loss_acum / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, testing_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    loss_acum = 0\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    N = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for iters, data in tqdm(\n",
    "            enumerate(testing_loader, 0), total=len(testing_loader)\n",
    "        ):\n",
    "            x = data[\"example\"].to(device)\n",
    "            targets = data[\"label\"].to(device)\n",
    "\n",
    "            # Make forward pass for prediction.\n",
    "            logits = model(x)\n",
    "            logits = logits.squeeze(1)\n",
    "            \n",
    "            loss = loss_fn(logits, targets.float())\n",
    "\n",
    "            # Compute accumulated loss for reporting progress.\n",
    "            loss_acum += loss.item()\n",
    "            N = N + 1\n",
    "\n",
    "            # Compute expected outputs vs model outputs for reporting progress.\n",
    "            # We use sigmoid activation as it is a binary classification problem.\n",
    "            fin_outputs.extend(torch.sigmoid(logits).cpu().detach().numpy())\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "\n",
    "    return loss_acum / N, np.array(fin_outputs), np.array(fin_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataframe to tabulate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = list(settings.keys())\n",
    "column_names = column_names + [\"seed\"]\n",
    "column_names = column_names + [\"epoch\"]\n",
    "column_names = column_names + [\"train_loss\"]\n",
    "\n",
    "if USE_VALIDATION_SET:\n",
    "    column_names = column_names + [\"val_loss\", \"val_accuracy\", \"val_f1_score_micro\", \"val_f1_score_macro\"]\n",
    "    \n",
    "column_names = column_names + [\"test_loss\", \"test_accuracy\", \"test_f1_score_micro\", \"test_f1_score_macro\"]\n",
    "column_names = column_names + [\"test_f1_score_label0\", \"test_f1_score_label1\"]\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_results = pd.DataFrame(columns=column_names)\n",
    "run_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Seed: {run_seed}\")\n",
    "np.random.seed(run_seed)\n",
    "torch.manual_seed(run_seed)\n",
    "random.seed(run_seed)\n",
    "\n",
    "training_set = CustomDataset(X_train, y_train)\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "\n",
    "if USE_VALIDATION_SET:\n",
    "    validation_set = CustomDataset(X_val, y_val)\n",
    "    validation_loader = DataLoader(validation_set, **validate_params)\n",
    "\n",
    "test_set = CustomDataset(X_test, y_test)\n",
    "testing_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create GRU with given settings\n",
    "_units = settings[\"UNITS\"]\n",
    "_num_layers = settings[\"GRU_NUM_LAYERS\"]\n",
    "_bidirectional = settings[\"BIDIRECTIONAL\"]\n",
    "_internal_dropout = settings[\"INTERNAL_DROPOUT\"]\n",
    "_dropout = settings[\"DROPOUT\"]\n",
    "\n",
    "model = FND_BI_GRU(\n",
    "    _emb_size=emb_size,\n",
    "    _units=_units,\n",
    "    _num_layers=_num_layers,\n",
    "    _num_categories=num_categories,\n",
    "    _bidirectional=_bidirectional,\n",
    "    _internal_dropout=_internal_dropout,\n",
    "    _dropout=_dropout\n",
    ")\n",
    "\n",
    "# TODO add config to load or not pre-trained weights\n",
    "# ####### LOAD PRE-TRAINED WEIGHTS #######\n",
    "if LOAD_PRETRAINED_MODEL and PRETRAINED_MODEL:\n",
    "    snapshot_download(f\"eprovidel/{PRETRAINED_MODEL}\", local_dir='./repo')\n",
    "    pattern = f\"./repo/{PRETRAINED_MODEL}*.pt\"\n",
    "    for filename in glob.glob(pattern, recursive=False):\n",
    "        print(f\"PRE-TRAINED WEIGHTS FOUND AT: {filename}\")\n",
    "        model.load_state_dict(torch.load(filename))\n",
    "        break\n",
    "\n",
    "print(\"Model\")\n",
    "print(model)\n",
    "model.to(device)\n",
    "\n",
    "_epochs = settings[\"EPOCHS\"]\n",
    "_epoch_snapshots = settings[\"EPOCH_SNAPSHOTS\"]\n",
    "_save_epoch_snapshots = settings[\"SAVE_EPOCH_SNAPSHOTS\"]\n",
    "_learning_rate = settings[\"LEARNING_RATE\"]\n",
    "\n",
    "optimizer = torch.optim.Adagrad(\n",
    "    params=model.parameters(),\n",
    "    lr=_learning_rate,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "scheduler = None\n",
    "\n",
    "for epoch in range(_epochs):\n",
    "    print(f\"===== EPOCH {epoch} / SEED {run_seed}\")\n",
    "\n",
    "    # ######################################################################################\n",
    "    # Train\n",
    "    train_loss = train(epoch, model, training_loader, optimizer, scheduler)\n",
    "    print(f\"Train loss: {train_loss}\")\n",
    "\n",
    "    # ######################################################################################\n",
    "    # Validation\n",
    "    if USE_VALIDATION_SET:\n",
    "        val_loss, val_outputs, val_targets = validate(model, validation_loader)\n",
    "        \n",
    "        val_outputs_bin = (val_outputs >= 0.5)\n",
    "        val_accuracy = metrics.accuracy_score(val_targets, val_outputs_bin)\n",
    "        val_f1_score_micro = metrics.f1_score(\n",
    "            val_targets, val_outputs_bin, average=\"micro\"\n",
    "        )\n",
    "        val_f1_score_macro = metrics.f1_score(\n",
    "            val_targets, val_outputs_bin, average=\"macro\"\n",
    "        )           \n",
    "    \n",
    "        print(f\"Accuracy Score = {val_accuracy}\")\n",
    "        print(f\"F1 Score (Micro) = {val_f1_score_micro}\")\n",
    "        print(f\"F1 Score (Macro) = {val_f1_score_macro}\")\n",
    "        print(f\"Validation loss:{val_loss}\")\n",
    "\n",
    "    # ######################################################################################\n",
    "    # Test\n",
    "    test_loss, test_outputs, test_targets = validate(model, testing_loader)\n",
    "    \n",
    "    test_outputs_bin = (test_outputs >= 0.5)\n",
    "    test_accuracy = metrics.accuracy_score(test_targets, test_outputs_bin)\n",
    "    test_f1_score_micro = metrics.f1_score(test_targets, test_outputs_bin, average='micro')\n",
    "    test_f1_score_macro = metrics.f1_score(test_targets, test_outputs_bin, average='macro')\n",
    "\n",
    "    # Per class f1_score_macro, when labels are binary.\n",
    "    test_f1_score_macro_binary0 = metrics.f1_score(test_targets, test_outputs_bin, average='binary', pos_label=0)\n",
    "    test_f1_score_macro_binary1 = metrics.f1_score(test_targets, test_outputs_bin, average='binary', pos_label=1)\n",
    "\n",
    "    print(f\"TEST Accuracy Score = {test_accuracy}\")\n",
    "    print(f\"TEST F1 Score (Micro) = {test_f1_score_micro}\")\n",
    "    print(f\"TEST F1 Score (Macro) = {test_f1_score_macro}\")\n",
    "    print(f\"TEST F1 Score (Macro) for label 0 = {test_f1_score_macro_binary0}\")\n",
    "    print(f\"TEST F1 Score (Macro) for label 1 = {test_f1_score_macro_binary1}\")\n",
    "    print(f\"TEST loss: {test_loss}\")\n",
    "\n",
    "    results_row = {\n",
    "        **settings,\n",
    "        'seed': run_seed,\n",
    "        'epoch': epoch,\n",
    "        'train_loss': train_loss,        \n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_f1_score_micro': test_f1_score_micro,\n",
    "        'test_f1_score_macro': test_f1_score_macro,\n",
    "        'test_f1_score_label0': test_f1_score_macro_binary0,\n",
    "        'test_f1_score_label1': test_f1_score_macro_binary1\n",
    "    }\n",
    "\n",
    "    if USE_VALIDATION_SET:\n",
    "        results_row = {\n",
    "            **results_row,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'val_f1_score_micro': val_f1_score_micro,\n",
    "            'val_f1_score_macro': val_f1_score_macro,\n",
    "        }        \n",
    "\n",
    "    run_results = pd.concat([run_results, pd.DataFrame([results_row])], ignore_index=True)\n",
    "\n",
    "    # ###############################################################\n",
    "    # Save epoch snapshot when required\n",
    "    if PAPERMILL:        \n",
    "        if SAVE_EPOCH_SNAPSHOTS:\n",
    "            if epoch in EPOCH_SNAPSHOTS:\n",
    "                print(f\"SAVING MODEL AT EPOCH SNAPSHOT: {epoch}\")\n",
    "                epoch_label = EPOCH_SNAPSHOTS_LABELS_BY_NUM.get(epoch, f\"epoch_{epoch}\")\n",
    "    \n",
    "                # Save model state with deepcopy\n",
    "                model_state = deepcopy(model.state_dict())\n",
    "                    \n",
    "                # Save model as native pytorch binary\n",
    "                new_model_repo_path = f\"FND_GRU_RNN_{RUN_SETTING:02d}_{epoch_label}_{epoch}_{RUN_SUFFIX}\"\n",
    "                print(f\"Saving model with path: {new_model_repo_path}\")\n",
    "                torch.save(model_state, f\"./{new_model_repo_path}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload all .pt files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STORE_RESULTS_S3 == 1:\n",
    "    !find ./ -name \"*.pt\" | xargs -I{} aws s3 cp ./{} s3://$S3_BUCKET/ --endpoint-url=$S3_ENDPOINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload all .pt files to huggingface hub as generic artifcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SAVE_EPOCH_SNAPSHOTS:\n",
    "    hfAPI = HfApi()\n",
    "    for filename in glob.glob('./*.pt', recursive=False):\n",
    "        try:\n",
    "            filename_base = os.path.basename(filename).split('.pt')[0]\n",
    "            print(f\"Uploading model {filename_base}\")    \n",
    "            repo = hfAPI.create_repo(f\"eprovidel/{filename_base}\", private=True)\n",
    "            hfAPI.upload_file(path_or_fileobj=f\"./{filename_base}.pt\", path_in_repo=f\"{filename_base}.pt\", repo_id=repo.repo_id)\n",
    "        except Exception as exc:\n",
    "            print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Save results to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PAPERMILL:\n",
    "    # Store results in Excel file\n",
    "    EXCEL_OUTPUT = f\"FND_GRU_RNN_{EXPERIMENT_SUFFIX}_{RUN_SETTING}_RUN_{RUN_SUFFIX}.xlsx\"\n",
    "    # !python send_bot.py f\"{EXCEL_OUTPUT} ready!\"\n",
    "    run_results.to_excel(f\"{XLS_RESULTS_FOLDER}/{EXCEL_OUTPUT}\")\n",
    "\n",
    "    if STORE_RESULTS_S3 == 1:\n",
    "        print(f\"Uploading {EXCEL_OUTPUT} to S3\")\n",
    "        # Upload results to S3. Depends on environment variables.\n",
    "        # We use $$ to force environment variable and to be able to combine it with local variable {EXCEL_OUTPUT}\n",
    "        !aws s3 cp ./{EXCEL_OUTPUT} s3://$$S3_BUCKET/ --endpoint-url=$$S3_ENDPOINT    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Remove .pt files to avoid filling the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
