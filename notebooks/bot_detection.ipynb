{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual setup of required environment variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env FND_ROOT=/workspace/fnd-building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define constants and import all randomness sources first.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration constants.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CUDA_DEVICE = 0\n",
    "\n",
    "# Global original seed for randomness reproducibility.\n",
    "OG_SEED = 30082010\n",
    "\n",
    "# Prefix for storing results.\n",
    "RUN_SUFFIX = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "# Total number of tweets available per author\n",
    "TOTAL_AUTHOR_LEN = 100\n",
    "\n",
    "# Absolute path to root folder of the repository.\n",
    "FND_ROOT=%env FND_ROOT\n",
    "\n",
    "DATA_PATH_PREFIX=f\"{FND_ROOT}/datasets/datasets-fnd-bot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize randomness sources with original seed, for full reproducibility of results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(OG_SEED)\n",
    "torch.manual_seed(OG_SEED)\n",
    "random.seed(OG_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All other imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import transformers\n",
    "\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "\n",
    "from torch import cuda\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "print(f\"Pytorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup papermill parameters.**\n",
    "The cell below must be tagged with the 'parameters' tag.\n",
    "See: https://papermill.readthedocs.io/en/latest/usage-parameterize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameters\n",
    "\n",
    "## Must be set to True when running via papermill.\n",
    "PAPERMILL = False\n",
    "\n",
    "## Seed to be used in CLM Building mode, where only 1 seed is used.\n",
    "INITIAL_SEED = 0\n",
    "\n",
    "## Name for saving model and tokenizer in huggingface hub.\n",
    "## Requires previous login using HF_TOKEN\n",
    "## Use command: huggingface-cli login --token $HF_TOKEN\n",
    "## where HF_TOKEN must be set as an environment variable with your login token.\n",
    "SAVE_CHECKPOINT_NAME=\"<user>/<model-tokenizer-name>\"\n",
    "\n",
    "## Whether to run as standalone task or as CLM building task.\n",
    "## Options: [\"standalone\", \"clm\"]\n",
    "# Standalone task:\n",
    "#      Use train and validation sets separately, for training an validation.\n",
    "#      Test with test set.\n",
    "# CLM building task:\n",
    "#      Merge train and validation sets for training, test with test set.\n",
    "RUN_MODE = \"standalone\"\n",
    "\n",
    "## Folder to store Excel result files\n",
    "XLS_RESULTS_FOLDER = \"./\"\n",
    "\n",
    "## Set to 1 to store results in S3, set to 0 otherwise.\n",
    "# Defaults to 0.\n",
    "STORE_RESULTS_S3 = 0\n",
    "\n",
    "## Parameters for saving and uploading results.\n",
    "EXPERIMENT_NAME = \"EXP-TBD\"\n",
    "RUN_SETTING = \"-1\"\n",
    "\n",
    "# Actual parameters for running the model\n",
    "\n",
    "## Language to use, options: [\"EN\", \"ES\"] for English and Spanish respectively.\n",
    "BOT_LANG = \"EN\"\n",
    "\n",
    "## Starting transformers checkpoint.\n",
    "# To use private checkpoints, user must be logged in\n",
    "# using the hugging-face-cli login method.\n",
    "CHECKPOINT = \"bert-base-uncased\" \n",
    "\n",
    "## Number of labels in the dataset\n",
    "NUM_LABELS = 2\n",
    "\n",
    "## Number of seeds to explore in standalone mode.\n",
    "SEEDS_NUM = 1\n",
    "\n",
    "## Maximum length for BERT tokens\n",
    "MAX_LEN = 512\n",
    "\n",
    "## Training parameters\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 1e-05\n",
    "DROPOUT = 0.1\n",
    "\n",
    "## Number of tweets to extract from each author\n",
    "# using the sampling strategy provided.\n",
    "AUTHOR_LEN = 15\n",
    "\n",
    "## Sampling strategy to use\n",
    "# when extracting AUTHOR_LEN tweets for each author.\n",
    "# Options: [\"head\", \"tail\", \"head+tail\"]-\n",
    "SAMPLING_STRATEGY = \"head\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clear CUDA cache and perform garbage collection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup CUDA device if GPU is available.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = f\"cuda:{CUDA_DEVICE}\" if cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(CUDA_DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure ekphrasis text preprocessor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_processor = TextPreProcessor(\n",
    "    \n",
    "    # terms that will be normalized\n",
    "    normalize=[\n",
    "        'url',\n",
    "        'email',\n",
    "        'percent',\n",
    "        'money',\n",
    "        'phone',\n",
    "        'user',\n",
    "        'time',\n",
    "        'date',\n",
    "        'number'\n",
    "    ],\n",
    "    \n",
    "    # terms that will be annotated\n",
    "    # annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\", 'emphasis', 'censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    # corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    # unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BERT-specific settings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_CONFIG = {\n",
    "    \"ignore_mismatched_sizes\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run-specific settings, taken from constants and papermill parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"OG_SEED\": OG_SEED,\n",
    "    \"SEEDS_NUM\": SEEDS_NUM,\n",
    "    \"INITIAL_SEED\": INITIAL_SEED,\n",
    "    \"CHECKPOINT\": CHECKPOINT,    \n",
    "    \"NUM_LABELS\": NUM_LABELS,    \n",
    "    \"MAX_LEN\": MAX_LEN,\n",
    "    \"DROPOUT\": DROPOUT,\n",
    "    \"TRAIN_BATCH_SIZE\": TRAIN_BATCH_SIZE,\n",
    "    \"VALID_BATCH_SIZE\": VALID_BATCH_SIZE,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "    \"AUTHOR_LEN\": AUTHOR_LEN,\n",
    "    \"SAMPLING_STRATEGY\": SAMPLING_STRATEGY,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"RUN SETTING: {RUN_SETTING}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PAPERMILL:\n",
    "    print(\"Importing plain tqdm\")\n",
    "    from tqdm import tqdm    \n",
    "else:\n",
    "    print(\"Importing auto tqdm\")\n",
    "    from tqdm.auto import tqdm    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom dataset loader and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Labels: Bot, Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx2label = [\"bot\", \"human\"]\n",
    "encoded_labels = LabelEncoder().fit_transform(idx2label)\n",
    "label2idx = dict(zip(idx2label, encoded_labels))\n",
    "label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_text_and_labels(jsonfile):\n",
    "    author_texts = []\n",
    "    labels = []\n",
    "    with open(jsonfile) as jsonf:\n",
    "        i = 0\n",
    "        for line in jsonf:\n",
    "            json_contents = json.loads(line)\n",
    "            author_texts.append(json_contents[\"text\"])\n",
    "            labels.append(json_contents[\"label\"])\n",
    "            i = i + 1\n",
    "        \n",
    "    return author_texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_strategy_handler(strategy):\n",
    "    \"\"\"Create an item builder based on the chosen strategy.\n",
    "\n",
    "    In all cases, AUTHOR_LEN tweets are inspected.\n",
    "    If AUTHOR_LEN < TOTAL_AUTHOR_LEN, the sampling is randomized without repetition.\n",
    "    \n",
    "    For each sampled tweet, N=MAX_LEN//TOTAL_AUTHOR_LEN\n",
    "    characters are extracted according to each strategy:\n",
    "\n",
    "    - head (default): the first N characters are extracted.\n",
    "    - tail: the last N characters are extracted.\n",
    "    - head+tail: the first//N2 are concatenated with the last N/2 characters.\n",
    "    \"\"\"\n",
    "    def sample_tweets(author_texts: List[str]):\n",
    "        \"\"\"Returns the sample of tweets to process.\n",
    "\n",
    "        If AUTHOR_LEN < TOTAL_AUTHOR_LEN, the sampling is randomized without repetition.\n",
    "        Otherwise, when AUTHOR_LEN == TOTAL_AUTHOR_LEN all tweets are returned, \n",
    "        however their order is randomized.\n",
    "        \"\"\"\n",
    "        sample = sample_without_replacement(TOTAL_AUTHOR_LEN, AUTHOR_LEN)\n",
    "        sampled_tweets = [author_texts[idx] for idx in sample]\n",
    "        return sampled_tweets\n",
    "\n",
    "    def extract_head(text, n):\n",
    "        extracted_text = text[0:n]\n",
    "        return extracted_text\n",
    "\n",
    "    def extract_tail(text, n):\n",
    "        extracted_text = text[len(text)-n:]\n",
    "        return extracted_text\n",
    "\n",
    "    def extract_head_tail(text, n):\n",
    "        extracted_text = f\"{extract_head(text, n//2)}{extract_tail(text,n//2)}\"\n",
    "        return extracted_text\n",
    "    \n",
    "    def item_builder(author_texts: List[str]):\n",
    "        N = MAX_LEN // AUTHOR_LEN\n",
    "        sampled_tweets = sample_tweets(author_texts)\n",
    "        extraction_function = None\n",
    "        if strategy == \"head\":\n",
    "            extraction_function = extract_head\n",
    "        elif strategy == \"tail\":\n",
    "            extraction_function = extract_tail\n",
    "        elif strategy == \"head+tail\":\n",
    "            extraction_function = extract_head_tail\n",
    "\n",
    "        assert extraction_function is not None\n",
    "        \n",
    "        extracted_tweets = list(map(lambda x: (extraction_function(\" \".join(text_processor.pre_process_doc(x)), N)), sampled_tweets))\n",
    "        return \" \".join(extracted_tweets)\n",
    "\n",
    "    return item_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, author_texts, labels, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.author_texts = author_texts\n",
    "        self.targets = labels        \n",
    "        self.max_len = max_len\n",
    "        self.item_builder = make_strategy_handler(settings[\"SAMPLING_STRATEGY\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.author_texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        author_texts = str(self.author_texts[index])        \n",
    "        split_author_texts = author_texts.split(\"<sep>\")[0:-1]       \n",
    "        \n",
    "        author_texts = self.item_builder(split_author_texts)\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            author_texts,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size': settings[\"TRAIN_BATCH_SIZE\"],\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}\n",
    "\n",
    "test_params = {\n",
    "    'batch_size': settings[\"VALID_BATCH_SIZE\"],\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert BOT_LANG in [\"EN\", \"ES\"]\n",
    "if BOT_LANG == \"EN\":\n",
    "    print(\"Loading dataset in English\")\n",
    "    TRAIN_TEXTS_FILE = f\"{DATA_PATH_PREFIX}/1_PAN19_bot_ep_training/PAN19_bot_ep_training_en.json\"\n",
    "    VALIDATION_TEXTS_FILE = f\"{DATA_PATH_PREFIX}/2_PAN19_bot_ep_test/PAN19_bot_ep_test_en.json\"\n",
    "    TEST_TEXTS_FILE = f\"{DATA_PATH_PREFIX}/3_PAN19_bot_ep_earlybirds/PAN19_bot_ep_earlybirds_en.json\"\n",
    "elif BOT_LANG == \"ES\":\n",
    "    print(\"Loading dataset in Spanish\")\n",
    "    TRAIN_TEXTS_FILE = f\"{DATA_PATH_PREFIX}/1_PAN19_bot_ep_training/PAN19_bot_ep_training_es.json\"\n",
    "    VALIDATION_TEXTS_FILE = f\"{DATA_PATH_PREFIX}/2_PAN19_bot_ep_test/PAN19_bot_ep_test_es.json\"\n",
    "    TEST_TEXTS_FILE = f\"{DATA_PATH_PREFIX}/3_PAN19_bot_ep_earlybirds/PAN19_bot_ep_earlybirds_es.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "author_texts_train, labels_train = make_text_and_labels(TRAIN_TEXTS_FILE)\n",
    "assert len(author_texts_train) == len(labels_train)\n",
    "print(f\"Total Training Tweets: {len(author_texts_train)}\")\n",
    "print(f\"Total Training Tweets with label 0: {len(list(filter(lambda x: x == 0, labels_train)))}\")\n",
    "print(f\"Total Training Tweets with label 1: {len(list(filter(lambda x: x == 1, labels_train)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "author_texts_val, labels_val = make_text_and_labels(VALIDATION_TEXTS_FILE)\n",
    "assert len(author_texts_val) == len(labels_val)\n",
    "print(f\"Total Validation Tweets: {len(author_texts_val)}\")\n",
    "print(f\"Total Validation Tweets with label 0: {len(list(filter(lambda x: x == 0, labels_val)))}\")\n",
    "print(f\"Total Validation Tweets with label 1: {len(list(filter(lambda x: x == 1, labels_val)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "author_texts_test, labels_test = make_text_and_labels(TEST_TEXTS_FILE)\n",
    "assert len(author_texts_test) == len(labels_test)\n",
    "print(f\"Total Test Tweets: {len(author_texts_test)}\")\n",
    "print(f\"Total Test Tweets with label 0: {len(list(filter(lambda x: x == 0, labels_test)))}\")\n",
    "print(f\"Total Test Tweets with label 1: {len(list(filter(lambda x: x == 1, labels_test)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLM Building Mode Only: Merge train and validation data into train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MODE == \"clm\":\n",
    "    author_texts_train = author_texts_train + author_texts_val\n",
    "    labels_train = labels_train + labels_val\n",
    "    assert len(author_texts_train) == len(labels_train)\n",
    "    print(f\"Total Merged Training Tweets: {len(author_texts_train)}\")\n",
    "    print(f\"Total Merged Training Tweets with label 0: {len(list(filter(lambda x: x == 0, labels_train)))}\")\n",
    "    print(f\"Total Merged Training Tweets with label 1: {len(list(filter(lambda x: x == 1, labels_train)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training, test, and validation procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, training_loader, optimizer = None, scheduler = None):\n",
    "    \n",
    "    model.train()\n",
    "    loss_acum = 0\n",
    "    N = 0\n",
    "    \n",
    "    for iters , data in tqdm(enumerate(training_loader, 0), total = len(training_loader)):\n",
    "\n",
    "        # Reset optimizer gradients.\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Get model input from custom dataset\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)        \n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        # Make forward and backward passes in the model.\n",
    "        outputs = model(ids, mask, token_type_ids)        \n",
    "        logits = outputs[\"logits\"]\n",
    "        loss = loss_fn(logits, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # Compute accumulated loss for reporting progress.\n",
    "        loss_acum += loss.item()\n",
    "        N = N + 1\n",
    "\n",
    "        # Update optimizer and scheduler, if any.\n",
    "        if optimizer:\n",
    "            optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "    return loss_acum / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation(model, testing_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    loss_acum=0\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    N = 0\n",
    "    \n",
    "    with torch.no_grad():        \n",
    "        for iters, data in tqdm(enumerate(testing_loader, 0),total = len(testing_loader)):            \n",
    "            # Get model input from custom dataset\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "            # Make forward pass for prediction\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            logits = outputs[\"logits\"]\n",
    "            loss = loss_fn(logits, targets)\n",
    "\n",
    "            # Compute accumulated loss for reporting progress.\n",
    "            loss_acum += loss.item()\n",
    "            N = N + 1\n",
    "\n",
    "            # Compute expected outputs vs model outputs for reporting progress.\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.softmax(logits, dim=1).cpu().detach().numpy())\n",
    "            \n",
    "    \n",
    "    return loss_acum / N, np.array(fin_outputs), np.array(fin_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate `settings[\"SEEDS_NUM\"]` seeds to explore model performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = np.random.randint(0, 42069, size=settings[\"SEEDS_NUM\"])\n",
    "seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If running in CLM building mode, set initial seed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_MODE == \"clm\":\n",
    "    seeds = [settings[\"INITIAL_SEED\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataframe to tabulate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = list(settings.keys())\n",
    "column_names = column_names + [\"seed\"]\n",
    "column_names = column_names + [\"epoch\"]\n",
    "column_names = column_names + [\"train_loss\"]\n",
    "column_names = column_names + [\"val_loss\", \"val_accuracy\", \"val_f1_score_micro\", \"val_f1_score_macro\"]\n",
    "column_names = column_names + [\"test_loss\", \"test_accuracy\", \"test_f1_score_micro\", \"test_f1_score_macro\"]\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_results = pd.DataFrame(columns=column_names)\n",
    "run_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Find best model across seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "best_valid_accuracy = 0\n",
    "best_valid_f1_macro = 0\n",
    "best_val_loss_epoch = None\n",
    "\n",
    "_checkpoint = settings[\"CHECKPOINT\"]\n",
    "_num_labels = settings[\"NUM_LABELS\"]\n",
    "_max_length = settings[\"MAX_LEN\"]\n",
    "_learning_rate = settings[\"LEARNING_RATE\"]\n",
    "_epochs = settings[\"EPOCHS\"]\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    # ###########################################\n",
    "    # ! Setup randomness to use current seed\n",
    "    print(f\"Setting seed: {seed}\")\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    # ###########################################\n",
    "\n",
    "    print(\"Train dataset statistics\")\n",
    "    print(\"Total Tweets: \", len(author_texts_train))\n",
    "    print(\"Label 0 (bot): \", len(list(filter(lambda x: x == idx2label[label2idx[\"bot\"]], labels_train))))\n",
    "    print(\"Label 1 (human): \", len(list(filter(lambda x: x == idx2label[label2idx[\"human\"]], labels_train))))\n",
    "\n",
    "    print(f\"Tokenizer: {_checkpoint}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(_checkpoint)\n",
    "    \n",
    "    training_set = CustomDataset(author_texts_train, labels_train, tokenizer, MAX_LEN)\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    \n",
    "    validation_set = CustomDataset(author_texts_val, labels_val, tokenizer, MAX_LEN)\n",
    "    validation_loader = DataLoader(validation_set, **train_params)\n",
    "    \n",
    "    test_set = CustomDataset(author_texts_test, labels_test, tokenizer, MAX_LEN)\n",
    "    testing_loader = DataLoader(test_set, **test_params)    \n",
    "\n",
    "    # Load pretrained model\n",
    "    print(f\"Model from: {_checkpoint} with {_num_labels} labels\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        _checkpoint,\n",
    "        num_labels=_num_labels,\n",
    "        **BERT_CONFIG\n",
    "    )    \n",
    "\n",
    "    print(\"Model config:\")\n",
    "    print(model.config)\n",
    "    \n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        params =  model.parameters(),\n",
    "        lr=_learning_rate,\n",
    "        weight_decay=0.01\n",
    "    )\n",
    "    \n",
    "    scheduler = None\n",
    "    \n",
    "    for epoch in range(_epochs):\n",
    "        print(f\"===== EPOCH {epoch} / SEED {seed}\")\n",
    "\n",
    "        # ######################################################################################\n",
    "        # Train        \n",
    "        train_loss = train(epoch, model, training_loader, optimizer, scheduler)\n",
    "        print(f\"Train loss: {train_loss}\")\n",
    "        \n",
    "        # ######################################################################################\n",
    "        # Validation: only in standalone task mode.\n",
    "        if RUN_MODE == \"standalone\":\n",
    "            val_loss, val_outputs, val_targets = validation(model,validation_loader)\n",
    "            \n",
    "            val_outputs_bin = np.argmax(val_outputs, axis=1)\n",
    "            val_accuracy = metrics.accuracy_score(val_targets, val_outputs_bin)\n",
    "            val_f1_score_micro = metrics.f1_score(val_targets, val_outputs_bin, average='micro')\n",
    "            val_f1_score_macro = metrics.f1_score(val_targets, val_outputs_bin, average='macro')\n",
    "            \n",
    "            if best_valid_loss > val_loss:\n",
    "                best_valid_loss = val_loss\n",
    "                best_val_loss_epoch = epoch\n",
    "                print(f\"Best val loss: {best_valid_loss} at epoch {epoch}\")\n",
    "    \n",
    "            print(f\"Validation Accuracy Score = {val_accuracy}\")\n",
    "            print(f\"Validation F1 Score (Micro) = {val_f1_score_micro}\")\n",
    "            print(f\"Validation F1 Score (Macro) = {val_f1_score_macro}\")\n",
    "            print(f'Validation loss:{val_loss}')\n",
    "        else:\n",
    "            val_loss = -1\n",
    "            val_accuracy = -1\n",
    "            val_f1_score_micro = -1\n",
    "            val_f1_score_macro = -1\n",
    "\n",
    "        # ######################################################################################\n",
    "        # Test with full test set\n",
    "        test_loss, test_outputs, test_targets = validation(model, testing_loader)\n",
    "        \n",
    "        test_outputs_bin = np.argmax(test_outputs, axis=1)\n",
    "        test_accuracy = metrics.accuracy_score(test_targets, test_outputs_bin)\n",
    "        test_f1_score_micro = metrics.f1_score(test_targets, test_outputs_bin, average='micro')\n",
    "        test_f1_score_macro = metrics.f1_score(test_targets, test_outputs_bin, average='macro')\n",
    "\n",
    "        print(f\"TEST Accuracy Score = {test_accuracy}\")\n",
    "        print(f\"TEST F1 Score (Micro) = {test_f1_score_micro}\")\n",
    "        print(f\"TEST F1 Score (Macro) = {test_f1_score_macro}\")\n",
    "        print(f\"TEST loss: {test_loss}\")\n",
    "\n",
    "        results_row = {\n",
    "            **settings,\n",
    "            'seed': seed,\n",
    "            'epoch': epoch,\n",
    "            'run_mode': RUN_MODE,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'val_f1_score_micro': val_f1_score_micro,\n",
    "            'val_f1_score_macro': val_f1_score_macro,\n",
    "            'test_loss': test_loss,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'test_f1_score_micro': test_f1_score_micro,\n",
    "            'test_f1_score_macro': test_f1_score_macro,\n",
    "        }\n",
    "\n",
    "        run_results = pd.concat([run_results, pd.DataFrame([results_row])], ignore_index=True)\n",
    "\n",
    "    # Save model to huggingface model hub. Only in CLM Building mode.\n",
    "    if RUN_MODE == \"clm\":\n",
    "        model.push_to_hub(SAVE_CHECKPOINT_NAME, private=True)\n",
    "        tokenizer.push_to_hub(SAVE_CHECKPOINT_NAME, private=True)\n",
    "            \n",
    "    del model    \n",
    "    del optimizer\n",
    "    del scheduler\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PAPERMILL:\n",
    "    # Store results in Excel file\n",
    "    EXCEL_OUTPUT = f\"{EXPERIMENT_NAME}_SETTING_{RUN_SETTING:02d}_RUN_{RUN_SUFFIX}.xlsx\"\n",
    "    run_results.to_excel(f\"{XLS_RESULTS_FOLDER}/{EXCEL_OUTPUT}\")\n",
    "\n",
    "    if STORE_RESULTS_S3 == 1:\n",
    "        # Upload results to S3. Depends on environment variables.\n",
    "        # We use $$ to force environment variable and to be able to combine it with local variable {EXCEL_OUTPUT}\n",
    "        !aws s3 cp {XLS_RESULTS_FOLDER}/{EXCEL_OUTPUT} s3://$$S3_BUCKET/ --endpoint-url=$$S3_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"END\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
